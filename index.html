<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>FAT/WEB</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="#overview" onclick="document.getElementById('mainPane').innerHTML=document.getElementById('overview').innerHTML;">FAT/WEB</a></h1>
        <p>Workshop on Fairness, Accountability, and Transparency on the Web<br><br>
            Perth, Australia</p>


        <p> <a href="#submissions"
        onclick="document.getElementById('mainPane').innerHTML=document.getElementById('submissions').innerHTML;">Submissions</a><br> <a href="#program"
        onclick="document.getElementById('mainPane').innerHTML=document.getElementById('program').innerHTML;">Program</a><br> <a href="#organization"
        onclick="document.getElementById('mainPane').innerHTML=document.getElementById('organization').innerHTML;">Organization</a><br> <a href="#related"
        onclick="document.getElementById('mainPane').innerHTML=document.getElementById('related').innerHTML;">Related
        Workshops</a><br> </p> 
    <p> <b>Important Dates</b><br> Submission: 10 Feb 2017<br> Acceptance: 24 Feb 2017<br> Camera Ready: 10 Mar 2017<br> Workshop: 3 or 4 April 2017</p>

              <a href="http://www2017.com.au/"><img src="WWW2017_logo.svg" width="200px" vspace="50"></a>
          
    </header> 
        <section> <div id="mainPane"></div> </section> 
    <footer> 
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
    <div id="overview" style="display:none">
        <h1>&nbsp;</h1>
        <p>Recent academic and journalistic reviews of online web services have revealed that many systems exhibit subtle biases reflecting historic discrimination.  Examples include racial and gender bias in search advertising, image recognition services, sharing economy mechanisms, pricing, and web-based delivery.  The list of production systems exhibiting biases continues to grow and may be endemic to the way models are trained and the data used.</p>
        <p>
            At the same time, concerns about user autonomy and fairness have been raised in the context of web-based experimentation such as A/B testing or explore/exploit algorithms.  Given the ubiquity of this practice and increasing adoption in potentially-sensitive domains (e.g. health, employment), user consent and risk will become fundamental to the practice.
        </p>
            Finally, understanding the reasons behind predictions and outcomes of web services is important in optimizing a system and in building trust with users.  However, it also has legal and ethical implications when the algorithm has an unintended or undesirable impact along social boundaries.</p>

<p>The objective of this full day workshop is to study and discuss the problems and solutions with algorithmic fairness, accountability, and transparency of models in the context of web-based services.</p>
    </div>
  <div id="program" style="display:none">
      <h1>Program</h1>
      <h2>TBD</h2>
  </div>
  <div id="submissions" style="display:none">
      <h1>Submissions</h1>
      <h2>Paper Topics</h2>
      <p>
          We invite submissions dealing with issues of,
          <ul>
              <li><strong>fairness</strong>: measuring and avoiding discrimination in web-based services,</li>
              <li><strong>accountability</strong>: auditing and proving socially-impactful properties of web-based services, and</li>
              <li><strong>transparency</strong>:  communicating the logic behind decisions of web-based services</li>
          </ul>
          with respect to methods (e.g. machine learning, experimentation, mechanism design) used in  the domains of main WWW 2017 conference,
          <ul>
              <li>Computational Health</li>
              <li>Crowdsourcing</li>
              <li>Internet Monetization and Online Markets</li>
              <li>Search</li>
              <li>Security and Privacy</li>
              <li>Semantics and Knowledge</li>
              <li>Social Network Analysis and Computational Social Science</li>
              <li>Systems and Infrastructure</li>
              <li>Ubiquitous and Mobile Computing</li>
              <li>User Modeling, Personalization and Experience</li>
              <li>Web Mining and Content Analysis</li>
          </ul>
          Topics might include auditing a web-based recommender system for demographic bias, requesting informed consent for A/B tests that potentially put the user at risk, and explaining algorithmic decisions to users without putting the system at risk.
    </p>
      <h2>Paper Types</h2>
      <p>Research in the area has begun to emerge in a variety of computer science subdisciplines.  Work can be divided into four groups,
      <ul>
      <li>
      <b>Case studies</b> consisting of concentrated quantitative or qualitative analyses of systems for ethically problematic behavior.<br>
      </li>
      <li>
      <b>Methods research</b>  studying quantitative approaches to defining and measuring fairness.  This work includes topics such as formally defining metrics and rigorously auditing systems.<br>
      </li>
      <li>
      <b>Tools</b> designed to detect ethically problematic behavior.  The majority of these methods use simulated users to conduct 'reverse A/B' tests on production systems.  These tools often implement techniques developed in methods work and help produce novel case studies.</li>
      <li>
      <b>Remedies</b>  designed to avoid ethically problematic behavior.  This work often adopts a metric developed in the methods work and designs an algorithm to balance, for example, fairness against revenue or accuracy.<br>
      </li>
      </ul>
  </p>

      <p>We strongly encourage submissions from researchers outside of the computer science community.</p>
      <h2>Format</h2>
      <p>Papers should be five page long with unlimited citations using the <a href="http://www.acm.org/sigs/publications/proceedings-templates">ACM SIG Proceedings template</a>.  Reviewing will be double-blind.  Authors should anonymize their paper before submission.</p>
      <h2>Submission</h2>
      <p>The conference reviewing system can be found at <a href="https://easychair.org/conferences/?conf=fatweb2017
">https://easychair.org/conferences/?conf=fatweb2017</a>.</p>
      <p>Accepted submissions will be made available to attendees but will not be published in an archival format.</p>
      
  </div>
  <div id="organization" style="display:none">
      <h1>Organization</h1>
           <h2>Chairs</h2>
           <p><a href="http://msr.nyc/fdiaz">Fernando Diaz</a> is a senior researcher at Microsoft Research and a founding member of the MSR-NYC lab.  Prior to joining Microsoft, Fernando was a senior scientist at Yahoo Research.  His primary research interest is formal information retrieval models and his research experience includes distributed information retrieval approaches to web search, interaction logging and modeling, interactive and faceted retrieval, mining of temporal patterns from news and query logs, cross-lingual information retrieval, graph-based retrieval methods, and synthesizing information from multiple corpora. He received a B.Sc. in Computer Science and a B.A. in Political Science, both from the University of Michigan, and a Ph.D. from the University of Massachusetts Amherst. His work on federation won the best paper awards at the WSDM 2009, SIGIR 2009, and ECIR 2011 conferences. His work on crisis informatics has received awards at SIGIR 2011 and ISCRAM 2013. He is a co-organizer of the Temporal Summarization track and Web track at TREC 2013-2015 and WSDM 2014.  He co-organized the WSDM 2015 Workshop on the Ethics of Online Experimentation.  </p>


           <p><a href="https://scholar.google.com/citations?user=rXY4178AAAAJ">Sara Hajian</a> is a research scientist at Eurecat Technology Center, Barcelona, Spain. She received her Ph.D. degree from Computer Engineering and Maths Department of the Universitat Rovira i Virgili (URV). She received her M.Sc. degree in Computer Science from Iran University of Science and Technology (IUST). She also had been a member of APA-IUTcert, an academic research and development center in the area of Network Security Vulnerabilities and Incident Handling. Her research interests are data mining methods and algorithms, social media and social network analysis, privacy-preserving data mining and publishing, and algorithmic bias (discovery and prevention of discrimination). She has been a visiting student at the Knowledge Discovery and Data Mining Laboratory (KDD-Lab), a joint research group of the Information Science and Technology Institute of the Italian National Research Council (CNR) in Pisa and the Computer Science Department of the University of Pisa. She has been a visiting scientist at Yahoo! Labs in Barcelona. The results of her research on algorithmic discrimination featured in Communications of ACM journal.  She co-organized the first IEEE ICDM International Workshop on Privacy and Discrimination in Data Mining (IEEE PDDM 2016). </p>


           <p><a href="https://staff.fnwi.uva.nl/m.derijke/">Maarten de Rijke</a> is professor of computer science at the Informatics Institute of the University of Amsterdam. His research is focused on information retrieval and his recent work covers semantic search, conversational search, and self-learning search engines. He holds MSc degrees in Philosophy and in  Mathematics, and a PhD degree in Computer Science, all from the University of Amsterdam. He previously worked at CWI and at the University of Warwick. Currently the editor-in-chief of ACM Transactions on Information Systems, Maarten has received many awards, grants and prizes for his research. He has previously co-organized workshops at CIKM, ECIR, SIGIR and WSDM. In 2017 he will be a co-organizer of the TREC Open Search track. He leads Amsterdam Data Science, which brings together research, education, and innovation activities around data science of four knowledge institutes in the Amsterdam area. He is also one of the initiators of a large 'responsible data science' initiative in the Netherlands.</p>
          
           <h2>Program Committee</h2>
      Solon Barocas, Microsoft Research, USA<br>
      Bettina Berendt, KU Leuven, Belgium<br>
      Joanna J Bryson, University of Bath, USA<br>
      Hal Daume, University of Maryland College Park, USA<br>
      Josep Doming-Ferrer, Universitat Rovira i Virgili, Spain<br>
      Sorelle Friedler, Haverford College, USA<br>
      Krishna Gummadi, MPI-SWS, Germany<br>
      Anna Lauren Hoffmann, University of California, Berkeley<br>
      Dirk Hovy, University of Copenhagen, Denmark<br>
      Toshihiro Kamishima, National Institute of Advanced Industrial Science and Technology, Japan<br>
      Joshua Kroll, CloudFlare, USA<br>
      Kristian Lum, Human Rights Data Analysis Group, USA<br>
      Alexandra Olteanu, Ecole Polytechnique Federale de Lausanne, Switzerland<br>
      Shannon L. Spruit, Delft University, Netherlands<br>
      Julia Stoyanovich, Drexel University, USA<br>
      Suresh Venkatasubramanian, University of Utah, USA<br>
      Christo Wilson, Northeastern University, USA<br>
      
  </div>
  <div id="related" style="display:none">
      <h1>Related Workshops</h1>
    <ul>
        <li><a href="http://www.fatml.org/">Fairness, Accountability, and Transparency
        in Machine Learning (FATML)</a></li>
        <li><a href="http://datworkshop.org/">Workshop on Data and Algorithmic Transparency</a></li>
        <li><a href="http://www.datatransparencylab.org/">Data Transparency Lab</a></li>
        <li><a href="http://www.mlandthelaw.org/">NIPS 2016 Symposium Machine Learning and the Law</a></li>
        <li><a href="https://sites.google.com/site/ethicsofonlineexperimentation/">WSDM 2016 Workshop on the Ethics of Online Experimentation</a></li>
        <li><a href="http://pddm16.eurecat.org/">ICDM 2016 International Workshop on Privacy and Discrimination in Data Mining</a></li>
        <li><a href="http://ethicsinnlp.com/">EACL 2017 Workshop on Ethics in Natural Language Processing</a></li>
    </ul>
      
  </div>
    <script>
        window.onload=function(){
            if(window.location.hash) {
document.getElementById('mainPane').innerHTML=document.getElementById(window.location.hash.split('#')[1]).innerHTML; 
            } else {
                document.getElementById('mainPane').innerHTML=document.getElementById('overview').innerHTML;
            }
         };
         window.onpopstate=function(){
             if(window.location.hash) {
 document.getElementById('mainPane').innerHTML=document.getElementById(window.location.hash.split('#')[1]).innerHTML; 
             } else {
                 document.getElementById('mainPane').innerHTML=document.getElementById('overview').innerHTML;
             }
          };
    </script>
</html>
